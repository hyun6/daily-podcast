import os
import uuid
import torch
import asyncio
import scipy.io.wavfile
from typing import Optional, Tuple
from qwen_tts.inference.qwen3_tts_model import Qwen3TTSModel

class QwenTTSHandler:
    """
    Handler for Qwen3 TTS generation using the local model.
    """
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(QwenTTSHandler, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if self._model is not None:
            return

        print("[QwenTTS] Initializing model...")
        self.device = "cpu" # "mps" if torch.backends.mps.is_available() else "cpu"
        print(f"[QwenTTS] Using device: {self.device}")
        
        try:
            # Load Qwen3-0.6B Base model
            # This will download from HF if not cached
            self.model = Qwen3TTSModel.from_pretrained(
                "Qwen/Qwen3-TTS-12Hz-0.6B-Base", 
                device_map=self.device
            )
            QwenTTSHandler._model = self.model
            print("[QwenTTS] Model loaded successfully.")
        except Exception as e:
            print(f"[QwenTTS] Failed to load model: {e}")
            raise e

    async def generate(self, text: str, ref_audio_path: str) -> str:
        """
        Generate audio from text using the reference audio for voice cloning.
        Runs in a separate thread to avoid blocking the event loop.
        """
        return await asyncio.to_thread(self._generate_sync, text, ref_audio_path)

    def _generate_sync(self, text: str, ref_audio_path: str) -> str:
        if not self.model:
            raise RuntimeError("QwenTTS model not initialized")

        print(f"[QwenTTS] Generating: '{text[:20]}...' with ref: {ref_audio_path}")
        
        # Qwen3 generation
        # Returns (wavs, sample_rate)
        # wavs is a list of numpy arrays (one for each input text)
        wavs, sample_rate = self.model.generate_voice_clone(
            text=text,
            ref_audio=ref_audio_path,
            x_vector_only_mode=True
        )

        if not wavs:
            raise RuntimeError("No audio generated by QwenTTS")

        # Save to file
        # We need a unique filename
        filename = f"{uuid.uuid4()}.wav"
        output_dir = os.path.join(os.path.dirname(__file__), "../../data/audio")
        
        # Ensure directory exists (it should, but just in case)
        os.makedirs(output_dir, exist_ok=True)
        
        output_path = os.path.join(output_dir, filename)
        
        # Save using scipy
        # wavs[0] is the numpy array for the first (and only) text
        scipy.io.wavfile.write(output_path, sample_rate, wavs[0])
        
        print(f"[QwenTTS] Saved to: {output_path}")
        return output_path

if __name__ == "__main__":
    # Test run
    async def test():
        handler = QwenTTSHandler()
        # Ensure we have a reference file from the previous step
        ref_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../data/voices/host_a.wav"))
        if not os.path.exists(ref_path):
            print(f"Reference file not found: {ref_path}")
            return
            
        path = await handler.generate("Hello world, this is a Qwen test.", ref_path)
        print(f"Generated file: {path}")

    asyncio.run(test())
